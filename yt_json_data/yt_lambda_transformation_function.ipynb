{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07e0bfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as wr\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "import os\n",
    "\n",
    "# Temporary AWS settings to be set as OS variable in AWS Lambda\n",
    "os_input_s3_cleansed_layer = os.environ['s3_cleansed_layer']\n",
    "os_input_glue_catalog_db_name = os.environ['glue_catalog_db_name']\n",
    "os_input_glue_catalog_table_name = os.environ['glue_catalog_table_name']\n",
    "os_input_write_data_operation = os.environ['write_data_operation']\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    # getting object from the event and showing its content type\n",
    "    bucket = event['Records'][0]['s3']['bucket']['name']\n",
    "    key = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'], encoding='utf-8')\n",
    "    \n",
    "    try:\n",
    "        # Creating df from content\n",
    "        df_json = wr.s3.read_json(f's3://{bucket}/{key}')\n",
    "        \n",
    "        # Extracting required columns\n",
    "        df_extract = pd.json_normalize(df_json['items'])\n",
    "        \n",
    "        # Writing to s3\n",
    "        wr_s3_response = wr.s3.to_parquet(df = df_extract,\n",
    "                                 path = os_input_s3_cleansed_layer,\n",
    "                                 dataset = True,\n",
    "                                 database = os_input_glue_catalog_db_name,\n",
    "                                 table = os_input_glue_catalog_table_name,\n",
    "                                 mode = os_input_write_data_operation\n",
    "                                )\n",
    "        return wr_s3_response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f'Error getting object {key} from the {bucket}')\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd0856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as wr\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "import os\n",
    "\n",
    "# Temporary AWS settings to be set as OS variable in AWS Lambda\n",
    "os_input_s3_cleansed_layer = os.environ('s3_cleansed_layer')\n",
    "os_input_glue_catalog_db_name = os.environ('glue_catalog_db_name')\n",
    "os_input_glue_catalog_table_name = os.environ('glue_catalog_table_name')\n",
    "os_input_write_data_operation = os.environ('write_data_operation')\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    # getting object from the event and showing its content type\n",
    "    bucket = event['Records'][0]['s3']['bucket']['name']\n",
    "    key = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'], encoding='utf-8')\n",
    "    \n",
    "    try:\n",
    "        # Creating df from content\n",
    "        df_json = wr.s3.read_json('s3://{}/{}'.format(bucket,key))\n",
    "        \n",
    "        # Extracting required columns\n",
    "        df_extract = pd.json_normalize(df_json['items'])\n",
    "        \n",
    "        # Writing to s3\n",
    "        wr_s3_response = wr.s3.to_parquet(df = df_extract,\n",
    "                                 path = os_input_s3_cleansed_layer,\n",
    "                                 dataset = True,\n",
    "                                 database = os_input_glue_catalog_db_name,\n",
    "                                 table = os_input_glue_catalog_table_name,\n",
    "                                 mode = os_input_write_data_operation\n",
    "                                )\n",
    "        return wr_s3_response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f'Error getting object {key} from the {bucket}')\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482a0fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Key\n",
    "\t\n",
    "Value\n",
    "glue_catalog_db_name\tdb_yt_cleaned\n",
    "glue_catalog_table_name\tyt_json_cleaned\n",
    "s3_cleansed_layer\ts3://yt-cleaned-data/youtube\n",
    "write_data_operation\tappend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb9d06d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f7a10a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf251e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c095ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa2a23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790cd98f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233d3b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f8a4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
